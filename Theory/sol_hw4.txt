1, 

The problem is to find the maximum log(n) values from n values in O(n) time.

What I think we can do is to apply a Min-Heap with size log(n). Read the n values one by one. If a value is larger than the head of the Min-heap, insert the value into the Min-heap and remove the head of the Min-heap. After all values are looped, the numbers in the Min-heap is the largest log(n) values.

Runtime: because the insert one value and poll one value out of the Min-heap both take O(log log n) time. The total runtime is O(n loglog n). Considering that loglog n increases extremely slow. We can consider loglog n to be a constant. E.X. when n = 10^100, loglog n = 5.4. Thus we can think the runtime of the above algorithm to be O(n). 

=================================================================

2,

A sorted array can be viewed itself as a priority queue. So if we always keep the structure of sorted array. Insert a values takes O(n) because you have to re-allocate the locations of values so that it remains sorted. Findmin takes O(1) because the min value is either the head or tail of the sorted array. Grabing any of these two takes O(1) time.


=================================================================

3

The case of two elements:
  We can use two pointers to do that. One pointer loops from begin to end, another pointer loops from end to begin. See the following algorithm:
  
  INPUT: Array with elements colored red or blue
  OUTPUT: A sorted array
  BEGIN:
    p1 <- 0
    p2 <- Array.length - 1
    while(p1 < p2):
      if Array[p1] is red:
        p1 <- p1 + 1
      else if Array[p1] is blue:
        switch(Array, p1, p2)
        p2 <- p2 - 1
  END


The case of three elements:
  Similarly, we can use three pointers to do that. p1 points to the end of red elements, p2 points to the end of blue elements, p3 points to the begin of black elements. The array will always look like:
  red red red blue blue blue  X  X  X   X  black black black
               p1            p2        p3

  INPUT: Array with elements colored red or blue or black
  OUTPUT: A sorted array
  BEGIN:
    p1 <- 0
    p2 <- 0
    p3 <- Array.length - 1
    while p2 < p3:
      while Array[p1] is red: 
        p1 <- p1 + 1
      if p2 < p1: p2 <- p1
      while Array[p2] is blue:
        p2 <- p2 + 1
      while Array[p3] is black:
        p3 <- p3 - 1
      if Array[p2] is red:
        switch(Array, p1, p2)
      else if Array[p2] is black:
        switch(Array, p2, p3)
  END

The algorithm above takes O(n) time because p2 only loop the array at most once.

=================================================================

4,

We can construct a Hash set whose key is the key of the collection of objects. Store the objects one by one into the Hash set. If two objects are equal, they have the same Hash value, so they will be stored to the same location. Loop through all objects, check whether the same objects have been inserted to the Hash set before, if not, insert the object to the Hash set. 

By looping through all objects once, the remaining values in the Hash set is without duplicates. Because insert takes only O(1) time for a Hash set. The runtime is O(n)

=================================================================


8, 

One way of pivot choosing is to choose pivot randomly. Another way of pivot choosing is to to choose the middle index of the partition.

The advantrage of random pivot choosing is that it guarantees low cost on average, however it cannot guarantee worst case performance. 

The advantage of middle index pivot choosing is that it is easy to implement, no requirement for random functions. It cannot guarantee worst case performance either. But it will have advantage on specific lists.

=================================================================

9,

One way is to attach words to images, and change the image search engine to word search engine. Because I cannot think of ways of compare the similarity of images.

Suppose we have a good method of comparing similarity of images. Then we can link all images similar to each other together.  


=================================================================

10,

This is a hard question. Intuitively by rebalancing every other operation we have less rebalancing operations. However, on the other hand every operation may needs to do more rotations.

So I think the runtime will remain the same, with tiny differences. Because the number of rotations needed to recover a balanced tree can be viewed as a fixed value. Whichever you do, either rotate for every operation or rotate for every other operation, in a long run the number of rotations should be the same. So runtime remain the same.
